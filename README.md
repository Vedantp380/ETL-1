# ETL Pipeline Using Spark, Airflow, and AWS EMR

This project demonstrates an ETL pipeline using Apache Spark, Apache Airflow, and AWS EMR. It reads CSV files from S3, performs transformations, and writes the results back to S3.

## Setup
- Configure Airflow for scheduling.
- Set up AWS EMR with Spark.
- Place CSV files in an S3 bucket.

## Usage
- Modify script with S3 bucket path.
- Run with Spark-submit on EMR.
- Monitor progress in Airflow.
---

# Financial Data Analysis with Spark SQL

This script reads financial data from a MySQL database using JDBC, performs analyses (revenue trends, expenses, profit margins, product performance), and saves results as CSV files in S3.

## Setup
- Modify JDBC URL, credentials, S3 path.
- Install Spark and dependencies.
- Run using spark-submit.

## Usage
- Clone repository.
- Install dependencies.
- Run script for analysis.

